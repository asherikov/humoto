\chapter{Optimization concepts}

This chapter introduces basic concepts and terms which commonly used in the
framework. The presentation is terse, so you may be interested in reading more
in other sources \cite{Sherikov2016phd, Dimitrov2015preprint, Saab2012tranrob,
Escande2014ijrr}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Tasks}\label{sec.tasks}

We define a \emph{task} as set of logically related constraints of the form
%
\begin{equation}
    \ubarV{\objb}
    \le
    \objA \x
    \le
    \barV{\objb},
\end{equation}
%
where $\objA \in \RR^{n \times m}$ is a given matrix; $\ubarV{\objb} \in \RR^n$
and $\barV{\objb} \in \RR^n$ are given vectors of lower and upper bounds, which
may include infinitely large values; and $\x \in \RR^m$ is a vector of decision
variables. We consider only well defined tasks where $\ubarV{\objb} \le
\barV{\objb}$ is always true.


Usually, control or optimization problems are composed of multiple tasks, which
may not be achieved exactly. In order to account for this we assume that there
exist implicit vector of violations $\violation \in \RR^n$ such that expression
%
\begin{equation}
    \ubarV{\objb}
    \le
    \objA \x
    -
    \violation
    \le
    \barV{\objb}
\end{equation}
%
is always exactly satisfied. A value in vector $\violation$ is negative when
the corresponding lower bound is violated, positive when the upper bound is
violated, and zero when the constraint is satisfied exactly. Here we aim at
satisfaction of a task in the least-squares sense, which is equivalent to
solving the following \ac{QP}
%
\begin{equation}
    \begin{aligned}
        \MINIMIZE{\x, \violation}   & \NORME{\violation}^2 \\
        \SUBJECTTO                  & \ubarV{\objb} \le \objA \x  -  \violation \le \barV{\objb}
    \end{aligned}
\end{equation}
%
for optimal $\violation^{\star}$. Note that due to semidefinite nature of this
problem $\x^{\star}$ is not necessarily unique.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Objectives: weighting of tasks}

Consider two tasks
%
\begin{equation}
    \ubarV{\objb}_1 \le \objA_1 \x \le \barV{\objb}_1
    \quad
    \mbox{and}
    \quad
    \ubarV{\objb}_2 \le \objA_2 \x \le \barV{\objb}_2,
\end{equation}
%
which are known to be in a conflict, \IE, cannot be satisfied exactly with zero
$\violation_1$ and $\violation_2$ simultaneously. In this case, we may still
want to satisfy the tasks simultaneously as much as possible with a certain
trade-off, which can be achieved with minimizaion of a weighted sum of the
norms of violations:
%
\begin{equation}
    \gamma_1
    \NORME{\violation_1}
    +
    \gamma_2
    \NORME{\violation_2},
\end{equation}
%
where $\gamma_1 \in \RR_{\ge 0}$ and $\gamma_2 \in \RR_{\ge 0}$. For example,
$\gamma_1 > \gamma_2$ gives higher priority to the first task.


We call a group of weighted tasks an \emph{objective}; note, however, that the
difference between a ``task'' and ``objective'' is purely terminological.
Usually, the weights are ommited since the necessary effect can be achieved by
scaling the task.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hierarchies: prioritization of tasks (objectives)}

In the previous section we considered case when we want to satisfy conflicting
tasks simultaneously, but what if one of the tasks has infinitely higher
priority than another? In this case we resort to \emph{hierarchies} of tasks or
objectives:
%
\begin{hierarchy}
    \level $\ubarV{\objb}_1 \le \objA_1 \x \le \barV{\objb}_1$
    \level $\ubarV{\objb}_2 \le \objA_2 \x \le \barV{\objb}_2$
    \level $\ubarV{\objb}_3 \le \objA_3 \x \le \barV{\objb}_3$
    \levelLabel{$\dots$} $\dots$
\end{hierarchy}
%
Here task (objective) $i$ is infinitely more important than task $i+1$, \IE,
satisfaction of task $i+1$ must never come at a price of increasing
$\NORME{\violation_i}^2$.


A hierarchy can be solved using a sequence of \ac{QP} or with the help of a
specialized algorithm~\cite{Dimitrov2015preprint}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Relation between hierarchies and QPs}

Note that a \ac{QP} can be represented as a hierarchy with two levels
%
\begin{hierarchy}
    \level $\ubarV{\objb}_1 \le \objA_1 \x \le \barV{\objb}_1$
    \level $\objA_2 \x = \V{\objb}_2$
\end{hierarchy}
%
where objective on the second level is an equality. The only difference is that
\ac{QP} requires the first inequality objective to be feasible. Since this
condition is satisfied in many applications, the framework allows to cast and
solve a hierarchy of two levels as a single \ac{QP}, even though this is not
strictly correct. This behavior can be suppressed by changing parameters of the
solvers.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computational performance}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Hot-starting}

Many solvers for optimization problems support hot-starting -- they accept
additional data, which may help to reduce computation time. Currently the
framework allows hot-starting using
%
\begin{itemize}
    \item a guess of the set of constraints, which are active at the solution;
    \item a guess of the solution.
\end{itemize}
%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Exploitation of the problem structure}

One of the ways to improve performance of the solver is to shape the
optimization problem in a beneficial manner and to inform the solver about the
structure of the problem.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Two-sided inequalities}

If a task is bounded from both sides it is beneficial to express it in the
following form
%
\begin{equation}
    \ubarV{\objb}
    \le
    \objA \x
    \le
    \barV{\objb}
\end{equation}
%
instead of splitting it into two parts corresponding to lower and upper bounds
as is common in practice:
%
\begin{equation}
    \begin{bmatrix}
        \objA\\
        -\objA\\
    \end{bmatrix}
    \x
    \le
    \begin{bmatrix}
        \barV{\objb}\\
        -\ubarV{\objb}
    \end{bmatrix}
\end{equation}
%
The reason for this is that bounds $\ubarV{\objb} < \barV{\objb}$ cannot be
violated simultaneously, which can be exploited by a solver to reduce
computational load.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Sparsity}

We call a task \emph{sparse} if the corresponding matrices and vectors contain
a large number of zeros. A task with simple bounds (box constraints) on the
decision variables
%
\begin{equation}
    \ubarV{\objb}
    \le
    \x
    \le
    \barV{\objb}
\end{equation}
%
is a typical example of a sparse task. Handling of such constraints can be
implemented in a very efficient way and is supported by many solvers. It is
often beneficial to reformulate an optimization problem in order to express
inequality tasks with simple bounds.

The framework does not support generic sparse matrices, but only specific
sparsity types listed in the table below
%
{\tabulinesep=1.2mm
\begin{longtabu}{c | c | c | c | c}
    Equality (zero)         &   Equality                &   Lower bounds                    &   Upper bounds                    &   Lower and upper bounds \\
    \hline
    $\objA \x = \V{0}$      &   $\objA \x = \V{\objb}$  &
                                                          $\ubarV{\objb} \le \objA \x$      &
                                                                                            $\objA \x \le \barV{\objb}$         &   $\ubarV{\objb} \le \objA \x \le \barV{\objb}$ \\
    \hline
    $\objA\M{S} \x = \V{0}$ &   $\objA\M{S} \x = \V{\objb}$ &
                                                            $\ubarV{\objb} \le \objA\M{S} \x$   &
                                                                                                $\objA\M{S} \x \le \barV{\objb}$    &   $\ubarV{\objb} \le \objA\M{S} \x \le \barV{\objb}$ \\
    \hline
    $\M{G} \x = \V{0}$      &   $\M{G} \x = \V{\objb}$  &   $\ubarV{\objb} \le \M{G} \x$    &   $\M{G} \x \le \barV{\objb}$     &   $\ubarV{\objb} \le \M{G} \x \le \barV{\objb}$ \\
    \hline
    $\M{I} \x = \V{0}$      &   $\M{I} \x = \V{\objb}$  &   $\ubarV{\objb} \le \M{I} \x$    &   $\M{I} \x \le \barV{\objb}$     &   $\ubarV{\objb} \le \M{I} \x \le \barV{\objb}$ \\
\end{longtabu}
}
%
\noindent Here $\M{S}$ selects a continuous segment of $\x$; $\M{G}$ is a
weighted selection matrix; $\M{I}$ is a simple selection matrix. Note that not
all sparsity types are supported by the solvers supported by the framework.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Early termination}

Some solvers support early termination by imposing a limit on the number of
iterations or computation time. Early termination is potentially dangerous
since the solution returned by the solver is suboptimal, \IE, some feasible
tasks may not be satisfied.
